{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf ./* ./.*\n",
        "# !git clone https://github.com/Kuduxaaa/ava-llm .\n",
        "!rm -rf checkpoints"
      ],
      "metadata": {
        "id": "FwypXPMfRZ8q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "import traceback\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "from ava import AvaConfig, AvaForCausalLM\n",
        "from ava.data.datasets import AvaDataset\n",
        "from ava.training.trainer import train_model\n",
        "from ava.utils import collate_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFQ2ilvyRdHy",
        "outputId": "809e94c3-5d71-446c-84e3-5500aaf74e37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ñë‚ñë      ‚ñë‚ñë‚ñë  ‚ñë‚ñë‚ñë‚ñë  ‚ñë‚ñë‚ñë      ‚ñë‚ñë\n",
            "‚ñí  ‚ñí‚ñí‚ñí‚ñí  ‚ñí‚ñí  ‚ñí‚ñí‚ñí‚ñí  ‚ñí‚ñí  ‚ñí‚ñí‚ñí‚ñí  ‚ñí\n",
            "‚ñì  ‚ñì‚ñì‚ñì‚ñì  ‚ñì‚ñì‚ñì  ‚ñì‚ñì  ‚ñì‚ñì‚ñì  ‚ñì‚ñì‚ñì‚ñì  ‚ñì\n",
            "‚ñà        ‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà        ‚ñà\n",
            "‚ñà  ‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà  ‚ñà\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = AvaConfig().apply_for('100m')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5QsFPFFU_cH",
        "outputId": "154b67e2-0f15-4bc9-b9ac-401fe570db90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config.vocab_size = len(tokenizer)\n",
        "config.pad_token_id = tokenizer.pad_token_id\n",
        "config.bos_token_id = tokenizer.bos_token_id or tokenizer.eos_token_id\n",
        "config.eos_token_id = tokenizer.eos_token_id\n",
        "\n",
        "print(f'Tokenizer vocabulary size: {len(tokenizer)}')\n",
        "print(f'Config vocabulary size: {config.vocab_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmtpUXHlVUWt",
        "outputId": "91d9985a-7fb4-4cd6-ff5b-e512b87d5cff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer vocabulary size: 50258\n",
            "Config vocabulary size: 50258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/data/oasst1_en_conv.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "data_small = data[:50]\n",
        "valid_data = []\n",
        "\n",
        "for conv in data_small:\n",
        "    if isinstance(conv, list) and len(conv) > 0:\n",
        "        valid_data.append(conv[0])\n",
        "\n",
        "print(f'Found {len(valid_data)}/{len(data_small)} valid conversations')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEVCLWRbVWt8",
        "outputId": "8c648e06-c399-4ef1-ea60-e58780761653"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 50/50 valid conversations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(valid_data)\n",
        "split_idx = int(len(valid_data) * 0.9)\n",
        "train_data = valid_data[:split_idx]\n",
        "val_data = valid_data[split_idx:]\n",
        "\n",
        "max_seq_length = 256\n",
        "train_dataset = AvaDataset(train_data, tokenizer, max_length=max_seq_length)\n",
        "val_dataset = AvaDataset(val_data, tokenizer, max_length=max_seq_length)\n",
        "\n",
        "print(f'Training dataset size: {len(train_dataset)}')\n",
        "print(f'Validation dataset size: {len(val_dataset)}')\n",
        "\n",
        "if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
        "    raise ValueError('Dataset is empty after processing. Check data format and filtering.')\n",
        "\n",
        "batch_size = 2\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = batch_size,\n",
        "    shuffle    = True,\n",
        "    collate_fn = collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size = batch_size,\n",
        "    collate_fn = collate_fn\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQbwmM0dVldq",
        "outputId": "0ec40722-c22f-46ff-c838-4c3445562ff2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size: 45\n",
            "Validation dataset size: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_batch = next(iter(train_loader))\n",
        "\n",
        "print(f'Sample batch shapes:')\n",
        "print(f'input_ids: {sample_batch[\"input_ids\"].shape}')\n",
        "print(f'attention_mask: {sample_batch[\"attention_mask\"].shape}')\n",
        "print(f'labels: {sample_batch[\"labels\"].shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0Weg-UmVu8a",
        "outputId": "b7ccc43e-1c0a-4fe1-b6f3-0e1700838009"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample batch shapes:\n",
            "input_ids: torch.Size([2, 256])\n",
            "attention_mask: torch.Size([2, 256])\n",
            "labels: torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_token_id = torch.max(sample_batch['input_ids']).item()\n",
        "print(f'Maximum token ID in batch: {max_token_id}')\n",
        "print(f'Tokenizer vocabulary size: {len(tokenizer)}')\n",
        "\n",
        "if max_token_id >= len(tokenizer):\n",
        "    raise ValueError(f'Maximum token ID {max_token_id} is out of range for vocabulary size {len(tokenizer)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idEyzG1RVxzX",
        "outputId": "1f5690b0-a80a-42bc-9bd5-8f5029a2f564"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum token ID in batch: 50257\n",
            "Tokenizer vocabulary size: 50258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AvaForCausalLM(config).to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 5e-5,\n",
        "    weight_decay = 0.01\n",
        ")"
      ],
      "metadata": {
        "id": "Y7qw4wvIV1Nn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    train_model(\n",
        "        model        = model,\n",
        "        train_loader = train_loader,\n",
        "        val_loader   = val_loader,\n",
        "        optimizer    = optimizer,\n",
        "        num_epochs   = 1,\n",
        "        device       = device\n",
        "    )\n",
        "\n",
        "    torch.save(model.state_dict(), 'ava_model_trained.pt')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f'‚ùå Training error: {e}')\n",
        "    traceback.print_exc()\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print('üôÑ As you wish, Sir!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM8CnOtrV3WY",
        "outputId": "0fa35a94-7730-4a38-ff9d-1c74da1598df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú® Starting training...\n",
            "üçÄ Epoch 1/1 | Batch 0/23 | Loss: 9.4651 | Time: 11.19s\n",
            "üçÄ Epoch 1/1 completed in 176.29s | Average Loss: 8.9878\n",
            "üíæ Checkpoint saved to checkpoints/ava_model_epoch_1.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Config: hidden_size={config.hidden_size}, num_attention_heads={config.num_attention_heads}, head_dim={config.head_dim}\")"
      ],
      "metadata": {
        "id": "XDYC5kAYXo1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = 'User: What is AI?\\nAssistant:'\n",
        "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "\n",
        "try:\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=100,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9\n",
        "    )\n",
        "\n",
        "    print(tokenizer.decode(output[0]))\n",
        "except Exception as e:\n",
        "    print(f'‚ùå Generation error: {e}')\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "AZe4r--OV5wJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}